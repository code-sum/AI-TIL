### [ACL 2025] Do LLMs Understand Dialogues? A Case Study on Dialogue Act [🗂️](https://aclanthology.org/2025.acl-long.1271/)


- 3줄 요약
  - LLM의 다자간 대화 행위(DA) 분류 성능이 낮은 원인을 분석하기 위해, 대화 이해에 필수적인 세 가지 선행 작업(Turn Management, Communicative Function, Dialogue Structure)을 정의하고 평가
  - 실험 결과, LLM은 이 선행 작업들에서 단순 규칙 기반 모델보다 성능이 낮거나 유사했으며, 화자 역할, 발화 기능, 대화 구조 파악에 어려움을 겪어 대화 이해 능력이 부족함을 드러냄
  - 이러한 선행 작업의 오류는 DA 분류 실패와 강한 상관관계를 보였고, 인간 연구를 통해 LLM과 인간의 대화 이해 능력 간 상당한 격차가 확인되어 대화 인지 훈련 전략 개선의 필요성을 강조

- 배경지식
  - Precision : 모델이 '참(Positive)'이라고 예측한 것들 중에서 실제로 '참'인 것들의 비율
  - Recall : 실제 '참(Positive)'인 것들 중에서 모델이 '참'으로 예측한 것들의 비율
  - F1 : Precision 과 Recall 의 조화평균
  - Accuracy : 전체 예측 중에서 올바르게 예측한 비율

- Dialogue Act?
  - 대화를 주고 받을 때 하나의 발화(turn)에 수반되는 행위적인 기능
  - 특히 인공지능 챗봇이나 음성 비서가 사람의 말을 정확하게 이해하고 적절하게 반응하기 위해 DA 를 분석하는 기술이 매우 중요하게 활용됨. 사용자가 "오늘 날씨 어때?"라고 물었을 때, 이를 '날씨 정보를 요청하는 질문'이라는 화행으로 파악해야 정확한 날씨 정보를 알려줄 수 있기 때문
 
- 문제의식
  - “Understanding DAs is a fundamental first step in analyzing and comprehending dialogues.”
  - “... significant gap between LLM and human-level dialogue understanding.”
  - 즉, DA 를 제대로 이해하는 것이 dialogue 를 분석하고 이해하는 첫단계임에도 불구하고, 현재 LLM 이 세분화된 DA 를 제대로 수행하지 못하고 결국 대화 이해 능력이 떨어진다고 진단
  - 기존 연구들도 LLM 의 대화 이해를 성능 측정하려고 노력하긴 했지만, 주로 two-party 대화에 초점을 맞춘다는 사실을 지적(ex. SwDA)

- Dialogue Act 를 정확히 분류하기 위한 3가지 Pre-tasks
  - (1) Turn Management(TM): 발화권 교체(turn taking). 두 사람 간 대화에서는 발화권 교체가 Speaker A > Speaker B 로 단순하게 모델링 되지만, 여러 명이 회의할 땐 중첩(overlap), 여러 사람의 동시 개입 같은 복잡한 상황이 발생
  - (2) Communicative Function(CF): 하나의 발화가 대화에서 무슨 역할을 하는가? (=과거에 반응하는가, 미래를 유도하는가?)
  - (3) Dialogue Structure(DS): 여러 발화들이 대화에서 어떻게 서로 짝을 이루어 연결되는가? (=질문-답변처럼 논리적인 짝이 있는가?)

- Experiment > Result
  - LLaMA-70B 와 같은 대규모 LLM 조차 DA 분류에서 125M 매개변수의 RoBERTa-base보다 훨씬 낮은 성능을 보였음
  - LLM 은 3가지 pre-tasks 에서 단순한 베이스라인 모델보다 성능이 낮거나 비슷하게 나옴
  - 특히, LLM 은 화자 교대 역할을 식별하는 데 어려움을 겪고, 발화의 고수준 의사소통 기능(특히 FLF)을 파악하지 못하며, 대화 구조를 예측할 때 먼 문맥 의존성을 포착하기보다 가까운 발화에 편향되는 경향을 보였음
  - 통계적 분석은 선행 작업에서의 오류가 DA 분류 오류와 강한 상관관계가 있음을 보여줌(p < 0.05)
  - 인간 주석자 연구에서 인간이 훈련 없이도 이러한 선행 작업에서 높은 일치도를 보이는 반면, LLM 은 인간 수준의 대화 이해와 상당한 격차를 보였음
  - 이는 LLM이 대화 맥락과 상호작용의 미묘한 차이를 이해하는 데 근본적인 한계가 있음을 시사하며, 개선된 대화 인식(dialogue-aware) 훈련 접근 방식의 필요성을 강조함

- Experiment > Setup

- Review & Next Step
