### [ACL 2025] Do LLMs Understand Dialogues? A Case Study on Dialogue Act [🗂️](https://aclanthology.org/2025.acl-long.1271/)


- 3줄 요약
  - LLM의 다자간 대화 행위(DA) 분류 성능이 낮은 원인을 분석하기 위해, 대화 이해에 필수적인 세 가지 선행 작업(Turn Management, Communicative Function, Dialogue Structure)을 정의하고 평가
  - 실험 결과, LLM은 이 선행 작업들에서 단순 규칙 기반 모델보다 성능이 낮거나 유사했으며, 화자 역할, 발화 기능, 대화 구조 파악에 어려움을 겪어 대화 이해 능력이 부족함을 드러냄
  - 이러한 선행 작업의 오류는 DA 분류 실패와 강한 상관관계를 보였고, 인간 연구를 통해 LLM과 인간의 대화 이해 능력 간 상당한 격차가 확인되어 대화 인지 훈련 전략 개선의 필요성을 강조

- Dialogue Act?
  - 대화를 주고 받을 때 하나의 발화(turn)에 수반되는 행위적인 기능
  - 특히 인공지능 챗봇이나 음성 비서가 사람의 말을 정확하게 이해하고 적절하게 반응하기 위해 Dialogue Act 를 분석하는 기술이 매우 중요하게 활용됨. 사용자가 "오늘 날씨 어때?"라고 물었을 때, 이를 '날씨 정보를 요청하는 질문'이라는 화행으로 파악해야 정확한 날씨 정보를 알려줄 수 있기 때문
 
- 문제의식
  - “Understanding DAs is a fundamental first step in analyzing and comprehending dialogues.”
  - “... significant gap between LLM and human-level dialogue understanding.”

- Dialogue Act 를 정확히 분류하기 위한 3가지 Pre-tasks
  - (1) Turn Management (TM)
  - (2) Communicative Function (CF)
  - (3) Dialogue Structure (DS)
