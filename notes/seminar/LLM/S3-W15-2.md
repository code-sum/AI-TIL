### [ICLR 2025] MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions [🗂️](https://openreview.net/forum?id=GGlpykXDCa)

- 3줄 요약
  - 기존 LLM 테이블 평가 벤치마크가 단일 테이블에 집중하여 실제 다중 테이블 시나리오의 복잡성을 반영하지 못함에 따라, 본 연구는 LLM의 다중 테이블 이해 및 추론 능력을 평가하기 위한 MMQA(Multi-table and Multi-hop Question Answering) 데이터셋을 소개
  - MMQA는 외래 키(foreign key)와 기본 키(primary key) 관계를 통해 여러 테이블에서 증거를 추출하는 다중 홉 추론을 요구하며, 다중 테이블 검색, Text-to-SQL 생성, 다중 테이블 QA, 그리고 Primary/Foreign Key 선택을 포괄하는 종합적인 평가 프레임워크를 제공
  - 실험 결과, 현재 LLM들은 MMQA 벤치마크에서 인간 성능에 크게 미치지 못하는 것으로 나타났지만, 본 연구가 제안하는 질문 분해(Question Decomposition) 기반의 새로운 다중 테이블 검색(MTR) 방법은 최첨단 성능을 달성

- MMQA
  - evaluation framework 은 2가지로 구성 (Fig 2)
    - (1) Multi-table Retrieval (MTR)
    - (2) Multi-table Evaluation
  - MMQA construction
    - Data Collection and Annotation
      - Spider DB (Yu et al., 2018a) 를 기반으로 MMQA 구축
        - Spider DB 는 Text-to-SQL Generation 작업을 위한 도메인간 복합 의미 분석 데이터셋
        - Spider DB 는 138개의 주제를 다루는 5693개 SQL 쿼리 + 다중 테이블로 구성된 200개 이상의 DB 로 구성
        - 이 논문은 Spider 에서 2-3개씩 묶은 table group sample 을 5000개 무작위 추출, 각 샘플에는 2~3개 테이블이 포함
    - Question Answer Annotation
    - Quality Verification
    - Question Categories
    - Reasoning Steps
