# [LLM] W1. Course Introduction

- 2025.09.04



- Transformer Architecture
  - NeurIPS 2017 에서 처음 발표
    - generic LM 에 활용된게 아니라, translation 에 활용하려는 수준이었음
    - 따라서 encoder, decoder 가 분리되어 있는 상태였음
      - encoder : 번역하기를 원하는 소스 데이터가 들어옴
      - decoder : 그 소스 데이터로부터 타깃 데이터, 즉 번역된 문장을 만들어냄