### [SIGCOMM 2024] NetLLM: Adapting Large Language Models for Networking [🗂️](https://arxiv.org/abs/2402.02338)


- 3줄 요약
  - 기존 딥러닝 기반 네트워킹 알고리즘은 높은 모델 엔지니어링 비용과 낮은 일반화 성능 문제를 겪고 있으며, 본 연구는 이러한 한계를 극복하기 위해 LLM 을 네트워킹 분야의 파운데이션 모델로 활용하는 NetLLM 프레임워크를 제안
  - NetLLM은 LLM이 다양한 네트워킹 데이터를 효과적으로 처리하도록 멀티모달 인코더를, 태스크별로 신뢰할 수 있고 효율적인 답변을 생성하도록 네트워킹 헤드를, 그리고 도메인 지식 습득 비용을 크게 줄이는 데이터 기반 저랭크 네트워킹 적응(DD-LRNA) 방식을 포함하는 통합 설계를 제공
  - NetLLM으로 적응된 LLM은 뷰포트 예측, 적응형 비트레이트 스트리밍, 클러스터 작업 스케줄링 등 세 가지 네트워킹 사용 사례 전반에 걸쳐 최첨단 알고리즘을 능가하는 성능과 뛰어난 일반화 능력을 보임
 
- Motivation
  - VP(viewport prediction): VR 에서 사용자 시선이 어딜 볼 것인지 미리 예측하고 고화질로 보여져야 하는 곳, 저화질로 보여져도 되는 곳에 각각 다른 화질의 영상을 전송하는 기술
  - ABR(adaptive bitrate streaming): 네트워크 상태에 따라 동영상 화질을 실시간으로 조정하는 기술
  - CJS(cluster job scheduling): 여러 대의 컴퓨터에게 어떤 일을, 어떤 컴퓨터가, 언제 처리할지 미리 정해주는 관리자
  - 각 Task 마다 DNN 모델 수동 설계 > 엔지니어링 오버헤드, 일반화 성능 저조 > LLM 의 가능성에 집중

- NetLLM 설계: 3가지 모듈로 구성
    1. 멀티모달 인코더: 네트워킹 입력을 토큰 임베딩으로 변환(이미지:ViT, 시계열:1D-CNN, 스칼라:FC, 그래프:GNN 등)
        - 💡이미지(Image)에는 Vision Transformer (ViT), 시계열(time-series) 및 시퀀스(sequence) 데이터에는 1D Convolutional Neural Network (1D-CNN), 스칼라(scalar) 데이터에는 Fully Connected Layer, 그래프(graph) 정보에는 Graph Neural Network (GNN)와 같은 modality-specific feature encoder를 재사용하여 특징(feature)을 추출. 추출된 특징들은 trainable linear layer와 Layer Normalization을 통해 LLM의 token space에 맞는 embedding 벡터로 투영됨. 예를 들어, Viewport Prediction (VP) 태스크의 경우 ViT와 1D-CNN이 이미지 및 시계열 뷰포트 데이터를 인코딩한 후, 별도의 linear projection layer를 통해 token-like embedding으로 변환됨
    2. 네트워킹 헤드: 기존 LLM의 LM헤드 대신, 과제별 변환기로서 직접적으로 과제에 맞는 답변(변수 범위 내) 생성
        - 💡네트워킹 헤드는 토큰 예측 방식을 없애고, 유효한 답변 범위(예: ABR에서 비트레이트 옵션 선택) 내에서 직접 답변을 생성하여 LLM의 신뢰성을 보장하고 답변 생성 지연 시간(latency)을 줄임. 예를 들어, ABR task 의 경우 Networking head는 비트레이트의 확률 분포를 직접 예측하여 단일 추론으로 유효한 비트레이트를 선택. VP 태스크의 경우 roll, pitch, yaw 값을 출력하는 세 개의 뉴런으로 구성
    3. DD-LRNA(Data-driven Low-Rank Networking Adaptation): 데이터 기반 적응 파이프라인 및 저차원 행렬로 파라미터 미세 조정(적은 학습 비용/메모리 소모)
        - LLM의 fine-tuning 비용을 획기적으로 줄이기 위한 scheme. 이 scheme 은 다음의 두 가지 핵심 디자인으로 구성
            - (1) Data-driven adaptation pipeline
            - (2) Low-rank adaptation
- LLM은 파라미터 동결 상태에서 위 인코더/헤드/저차원 행렬만 미세 조정
