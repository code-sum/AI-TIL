# 🎓AI 강의노트

> - KAIST | AI College
> - Yonsei University | College of Computing



## 1. [Basic] Python Programming

[Lectures]

- [Python 기초](0424_PythonBasic.md)
- [if 조건문, while 반복문](0425_IfWhile.md)
- [함수, 자료형, 변수, 라이브러리](0426_FuncLib.md)
- [지역 변수, 전역 변수, 리스트, 튜플](0427_Variables.md)
- [리스트, 튜플, 문자열, 사전, 집합](0428_ListTuple.md)
- [문자열, 집합, 사전, 모듈, 그래픽 객체](0501_StrDict.md)
- [사전형, 집합, 텍스트, 이미지, 그래픽](0502_ImgGraphic.md)
- [텍스트, 이미지, 그래픽, 클래스](0503_Class.md)
- [전체 복습 (4/24 ~ 5/7)](0509_Review.md)
- [실습문제 풀이 (4/24 ~ 5/7)](0510_QAPractice.md)

[Practices]

- [4월30일-A반-실습자료](0430_Practice1.md)
- [5월07일-A반-실습자료](0507_Practice2.md)



## 2. [Basic] Python DP / DA / DV 

> Data Processing, Data Analysis, Data Visualization

- [NumPy 표준 데이터 타입](0511_NumPy.md)
- [NumPy 배열의 기초](0512_NumPy2.md)
- [Pandas 객체소개 및 심화](0515_Pandas.md)
- [Matplotlib](0517_Matplotlib.md)



## 3. [Advanced] Recent Advances in Multimodal Deep Learning

- W3 - 9/16
  - [CVPR 2025] RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models
  - [CVPR 2024] InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks
  - [CVPR 2025] Flowing from Words to Pixels: A Noise-Free Framework for Cross-Modality Evolution
  - [ICASSP 2023] Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation
- W4 - 9/23
  - [CVPR 2025] MMaDA: Multimodal Large Diffusion Language Models
  - dd
- W5 - 9/30
  - dd
  - dd



## 4. [Advanced] Recent Advances in LLMs
> Candidate Award-Winning Papers
> - [ACL 2025 award papers](https://2025.aclweb.org/program/awards/)
> - [ACL 2024 award papers](https://2024.aclweb.org/program/best_papers/)
> - [EMNLP 2024 award papers](https://2024.emnlp.org/program/best_papers/)

[Useful References]
- Lectures of other univ., e.g., Language Models (https://stanford-cs324.github.io)
- Blog by other researchers, e.g., in OpenAI (https://lilianweng.github.io)
- E-mail subscription for recently issued papers (https://nlp.elvissaravia.com)

[Session 1.]
- W1 - 9/4
  - [Course Introduction & Basics of LLMs](seminar/LLM/S1-W1-1.md)
- W2 - 9/11
  - [ACL 2025] LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts (note) [(link)](https://aclanthology.org/2025.acl-long.1207/)
  - [ACL 2025] Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions (note) [(link)](https://aclanthology.org/2025.acl-long.182/)
  - [ACL 2025] Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral (note) [(link)](https://aclanthology.org/2025.acl-long.294/)
- W3 - 9/18
  - [ACL 2025] From REAL to SYNTHETIC: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding (note) [(link)](https://aclanthology.org/2025.acl-long.517/)
  - [EMNLP 2024] Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (note) [(link)](https://arxiv.org/abs/2410.12284)
  - [ACL 2025] Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users (note) [(link)](https://aclanthology.org/2025.acl-long.1260/)
  - [ACL 2024] Don’t Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration (note) [(link)](https://aclanthology.org/2024.acl-long.786.pdf)
  - [ICLR 2025] Safety Alignment Should be Made More Than Just a Few Tokens Deep (note) [(link)](https://openreview.net/forum?id=6Mxhg9PtDE)
  - [ACL 2024] Having Beer after Prayer? Measuring Cultural Bias in Large Language Models (note) [(link)](https://aclanthology.org/2024.acl-long.862.pdf)
  - [ACL 2025] Mixtures of In-Context Learners (note) [(link)](https://aclanthology.org/2025.acl-long.1277/)
  - [ACL 2025] Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively (note) [(link)](https://arxiv.org/pdf/2506.00396?)
- W4 - 9/25
  - [ACL 2025] A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive (note) [(link)](https://aclanthology.org/2025.acl-long.1454/)
  - [ACL 2024] Steering Llama 2  via Contrastive Activation Addition (note) [(link)](https://aclanthology.org/2024.acl-long.828/)
  - Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models
  - Do LLMs Understand Dialogues? A Case Study on Dialogue Act
  - Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
  - Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs
  - Mission: Impossible Language Models
  - HALoGEN: Fantastic LLM Hallucinations and Where to find them
  - FloorPlan-LLaMa: Aligning Architects’ Feedback and Domain Knowledge in Architectural Floor Plan Generation
- W5 - 10/2
- W6 - 10/9 (Online)

[Session 2.]
- dd

[Session 3.]
- dd
