# 🎓AI 강의노트

> - KAIST | AI College
> - Yonsei University | College of Computing



## 1. [Basic] Python Programming

[Lectures]

- [Python 기초](0424_PythonBasic.md)
- [if 조건문, while 반복문](0425_IfWhile.md)
- [함수, 자료형, 변수, 라이브러리](0426_FuncLib.md)
- [지역 변수, 전역 변수, 리스트, 튜플](0427_Variables.md)
- [리스트, 튜플, 문자열, 사전, 집합](0428_ListTuple.md)
- [문자열, 집합, 사전, 모듈, 그래픽 객체](0501_StrDict.md)
- [사전형, 집합, 텍스트, 이미지, 그래픽](0502_ImgGraphic.md)
- [텍스트, 이미지, 그래픽, 클래스](0503_Class.md)
- [전체 복습 (4/24 ~ 5/7)](0509_Review.md)
- [실습문제 풀이 (4/24 ~ 5/7)](0510_QAPractice.md)

[Practices]

- [4월30일-A반-실습자료](0430_Practice1.md)
- [5월07일-A반-실습자료](0507_Practice2.md)



## 2. [Basic] Python DP / DA / DV 

> Data Processing, Data Analysis, Data Visualization

- [NumPy 표준 데이터 타입](0511_NumPy.md)
- [NumPy 배열의 기초](0512_NumPy2.md)
- [Pandas 객체소개 및 심화](0515_Pandas.md)
- [Matplotlib](0517_Matplotlib.md)



## 3. [Advanced] Recent Advances in Multimodal Deep Learning

- W3 - 9/16
  - RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models (CVPR 2025)
  - InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks (CVPR 2024)
  - Flowing from Words to Pixels: A Noise-Free Framework for Cross-Modality Evolution (CVPR 2025)
  - Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation
- W4 - 9/23
  - dd
  - dd
- W5 - 9/30
  - dd
  - dd



## 4. [Advanced] Recent Advances in LLMs
> Candidate Award-Winning Papers
> - [ACL 2025 award papers](https://2025.aclweb.org/program/awards/)
> - [ACL 2024 award papers](https://2024.aclweb.org/program/best_papers/)
> - [EMNLP 2024 award papers](https://2024.emnlp.org/program/best_papers/)

[Useful References]

- Lectures of other univ., e.g., Language Models (https://stanford-cs324.github.io)
- Blog by other researchers, e.g., in OpenAI (https://lilianweng.github.io)
- E-mail subscription for recently issued papers (https://nlp.elvissaravia.com)

[Session 1.]

- W1 - 9/4
  - [Course Introduction & Basics of LLMs](seminar/LLM/S1-W1-1.md)
- W2 - 9/11
  - [LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts](https://aclanthology.org/2025.acl-long.1207/)
  - [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://aclanthology.org/2025.acl-long.182/)
  - [Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral](https://aclanthology.org/2025.acl-long.294/)
- W3 - 9/18
  - From REAL to SYNTHETIC: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding
  - Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users
  - Don’t Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration
  - Safety Alignment Should be Made More Than Just a Few Tokens Deep
  - Having Beer after Prayer? Measuring Cultural Bias in Large Language Models
  - Mixtures of In-Context Learners
  - Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively
  - A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive
- W4 - 9/25
  - Steering Llama 2  via Contrastive Activation Addition
  - Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models
  - Do LLMs Understand Dialogues? A Case Study on Dialogue Act
  - Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
  - Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs
  - Mission: Impossible Language Models
  - HALoGEN: Fantastic LLM Hallucinations and Where to find them
  - FloorPlan-LLaMa: Aligning Architects’ Feedback and Domain Knowledge in Architectural Floor Plan Generation
- W5 - 10/2
- W6 - 10/9 (Online)

[Session 2.]

- dd

[Session 3.]
- dd
