# ðŸŽ“AI ê°•ì˜ë…¸íŠ¸

> - KAIST | AI College
> - Yonsei University | College of Computing

## 1. [Basic] Python Programming

[Lectures]

- [Python ê¸°ì´ˆ](0424_PythonBasic.md)
- [if ì¡°ê±´ë¬¸, while ë°˜ë³µë¬¸](0425_IfWhile.md)
- [í•¨ìˆ˜, ìžë£Œí˜•, ë³€ìˆ˜, ë¼ì´ë¸ŒëŸ¬ë¦¬](0426_FuncLib.md)
- [ì§€ì—­ ë³€ìˆ˜, ì „ì—­ ë³€ìˆ˜, ë¦¬ìŠ¤íŠ¸, íŠœí”Œ](0427_Variables.md)
- [ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë¬¸ìžì—´, ì‚¬ì „, ì§‘í•©](0428_ListTuple.md)
- [ë¬¸ìžì—´, ì§‘í•©, ì‚¬ì „, ëª¨ë“ˆ, ê·¸ëž˜í”½ ê°ì²´](0501_StrDict.md)
- [ì‚¬ì „í˜•, ì§‘í•©, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ê·¸ëž˜í”½](0502_ImgGraphic.md)
- [í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ê·¸ëž˜í”½, í´ëž˜ìŠ¤](0503_Class.md)
- [ì „ì²´ ë³µìŠµ (4/24 ~ 5/7)](0509_Review.md)
- [ì‹¤ìŠµë¬¸ì œ í’€ì´ (4/24 ~ 5/7)](0510_QAPractice.md)

[Practices]

- [4ì›”30ì¼-Aë°˜-ì‹¤ìŠµìžë£Œ](0430_Practice1.md)
- [5ì›”07ì¼-Aë°˜-ì‹¤ìŠµìžë£Œ](0507_Practice2.md)

## 2. [Basic] Python DP / DA / DV

> Data Processing, Data Analysis, Data Visualization

- [NumPy í‘œì¤€ ë°ì´í„° íƒ€ìž…](0511_NumPy.md)
- [NumPy ë°°ì—´ì˜ ê¸°ì´ˆ](0512_NumPy2.md)
- [Pandas ê°ì²´ì†Œê°œ ë° ì‹¬í™”](0515_Pandas.md)
- [Matplotlib](0517_Matplotlib.md)

## 3. [Advanced] Recent Advances in Multimodal Deep Learning

[Session 1.] w/Professor Hwang

- W3 - 9/16
  - [CVPR 2025] RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models [(note)](seminar/MM/S1-W3-1.md) [(link)](https://arxiv.org/abs/2410.13360)
  - [CVPR 2024] InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks [(note)](seminar/MM/S1-W3-2.md) [(link)](https://arxiv.org/abs/2312.14238)
  - [CVPR 2025] Flowing from Words to Pixels: A Noise-Free Framework for Cross-Modality Evolution [(link)](https://arxiv.org/abs/2412.15213)
  - [ICASSP 2023] Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation [(link)](https://arxiv.org/abs/2211.06687)
- W4 - 9/23
  - [CVPR 2025] LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning [(link)](https://arxiv.org/abs/2505.16933)
  - [CVPR 2025] The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models? [(link)](https://arxiv.org/abs/2504.04540)
  - [CVPR 2025] Cross-modal Information Flow in Multimodal Large Language Models [(link)](https://arxiv.org/abs/2411.18620)
  - [CVPR 2025] Tackling View-Dependent Semantics in 3D Language Gaussian Splatting [(link)](https://arxiv.org/abs/2505.24746)
- W5 - 9/30
  - [ICLR 2023] Contrastive Audio-Visual Masked Autoencoder [(link)](https://arxiv.org/abs/2210.07839)
  - [CVPR 2025] Towards Zero-shot Anomaly Detection and Reasoning with Multimodal Large Language Models [(link)](https://arxiv.org/abs/2502.07601)
  - [CVPR 2025] Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration [(link)](https://arxiv.org/abs/2502.16652)
- W7 - 10/14
  - [ICLR 2025] Reducing Hallucinations in Large Vision Language Models via Latent Space Steering [(link)](https://arxiv.org/abs/2410.15778)
  - [CVPR 2025] MBQ: Modality-Balanced Quantization for Large Vision-Language Models [(link)](https://arxiv.org/abs/2412.19509)
  - [IEEE Transactions on Pattern Analysis and Machine Intelligence] Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts [(link)](https://arxiv.org/abs/2405.11273)
- W7 - 10/15
  - [arXiv 2023] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control [(link)](https://arxiv.org/abs/2307.15818)
  - [ICCV 2025] V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models [(link)](https://arxiv.org/abs/2508.03254)
- W9 - 10/28
  - [CVPR 2025] LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models [(link)](https://arxiv.org/abs/2501.18954)
  - [NSDI 2024] DistMM: Accelerating Distributed Multimodal Model Training [(link)](https://www.usenix.org/conference/nsdi24/presentation/huang)
  - [Microsoft 2025] ModServe: Modality- and Stage-Aware Resource Disaggregation for Scalable Multimodal Model Serving [(link)](https://arxiv.org/abs/2502.00937)
  - [SIGCOMM 2024] NetLLM: Adapting Large Language Models for Networking [(note)](seminar/MM/S1-W9-4.md) [(link)](https://arxiv.org/abs/2402.02338)

[Session 2.] w/Professor Park

- W10 - 11/4
  - [ICLR 2024] Uni3D: Exploring Unified 3D Representation at Scale [(link)](https://arxiv.org/abs/2310.06773)
  - [ACL 2025] Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues [(link)](https://arxiv.org/abs/2506.00958)
  - [NeurIPS 2025] The VLLM Safety Paradox: Dual Ease in Jailbreak Attack and Defense [(link)](https://arxiv.org/abs/2411.08410)
  - [CVPR 2024] OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation [(link)](https://arxiv.org/abs/2311.17911)
- W11 - 11/11
  - [ICCV 2025] TACA: Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers [(link)](https://arxiv.org/abs/2506.07986)
  - [ICML 2025] Diving into Self-Evolving Training for Multimodal Reasoning [(link)](https://arxiv.org/abs/2412.17451)
  - [NeurIPS 2025] GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents [(link)](https://arxiv.org/abs/2505.15810)
  - [NeurIPS 2024] HEALNet: Multimodal Fusion for Heterogeneous Biomedical Data [(link)](https://arxiv.org/abs/2311.09115)
- W12 - 11/18
  - [arXiv 2024] Can AI Perceive Physical Danger and Intervene? [(link)](https://arxiv.org/abs/2509.21651)
  - [ECCV 2024] Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection [(link)](https://arxiv.org/abs/2303.05499)
  - [ECCV 2024] On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models [(link)](https://arxiv.org/abs/2510.09008)
  - [ICLR 2025] LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token [(link)](https://arxiv.org/abs/2501.03895)
- W13 - 11/25
  - [CHI 2024] OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs [(link)](https://arxiv.org/abs/2405.03901)
  - [EMNLP 2025] ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering [(link)](https://arxiv.org/abs/2505.23242)
  - [arXiv 2025] Multimodal Safety Evaluation in Generative Agent Social Simulations [(link)](https://arxiv.org/abs/2510.07709)
  - [CVPR 2025] Multi-subject Open-set Personalization in Video Generation [(link)](https://arxiv.org/abs/2501.06187)
- W14 - 12/2
  - [RSS 2025] Ï€_0: A Vision-Language-Action Flow Model for General Robot Control [(link)](https://arxiv.org/abs/2410.24164)
  - [NeurIPS 2025] PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding [(link)](https://arxiv.org/abs/2505.20759)
  - [ICLR 2023] Uni-Mol: A Universal 3D Molecular Representation Learning Framework [(link)](https://openreview.net/forum?id=6K2RM6wVqKu)
  - [arXiv 2024] MoE-LLaVA: Mixture of Experts for Large Vision-Language Models [(link)](https://arxiv.org/abs/2401.15947)

## 4. [Advanced] Recent Advances in LLMs

> Candidate Award-Winning Papers
>
> - [ACL 2025 award papers](https://2025.aclweb.org/program/awards/)
> - [ACL 2024 award papers](https://2024.aclweb.org/program/best_papers/)
> - [EMNLP 2024 award papers](https://2024.emnlp.org/program/best_papers/)

[Useful References]

- Lectures of other univ., e.g., Language Models (https://stanford-cs324.github.io)
- Blog by other researchers, e.g., in OpenAI (https://lilianweng.github.io)
- E-mail subscription for recently issued papers (https://nlp.elvissaravia.com)

[Session 1] w/Professor Yeo

- W1 - 9/4
  - [Course Introduction & Basics of LLMs](seminar/LLM/S1-W1-1.md)
- W2 - 9/11
  - [ACL 2025] LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts [(note)](seminar/LLM/S1-W2-1.md) [(link)](https://aclanthology.org/2025.acl-long.1207/)
  - [ACL 2025] Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models (note) [(link)](https://aclanthology.org/2025.acl-long.533/)
  - âœ…[ACL 2025] Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral (note) [(link)](https://aclanthology.org/2025.acl-long.294/)
- W3 - 9/18
  - âœ…[ACL 2025] From REAL to SYNTHETIC: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding (note) [(link)](https://aclanthology.org/2025.acl-long.517/)
  - âœ…[EMNLP 2024] Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting (note) [(link)](https://arxiv.org/abs/2410.12284)
  - [ACL 2025] Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users (note) [(link)](https://aclanthology.org/2025.acl-long.1260/)
  - âœ…[ACL 2024] Donâ€™t Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration (note) [(link)](https://aclanthology.org/2024.acl-long.786.pdf)
  - âœ…[ICLR 2025] Safety Alignment Should be Made More Than Just a Few Tokens Deep (note) [(link)](https://openreview.net/forum?id=6Mxhg9PtDE)
  - âœ…[ACL 2024] Having Beer after Prayer? Measuring Cultural Bias in Large Language Models (note) [(link)](https://aclanthology.org/2024.acl-long.862.pdf)
  - âœ…[ACL 2025] Mixtures of In-Context Learners (note) [(link)](https://aclanthology.org/2025.acl-long.1277/)
  - âœ…[ACL 2025] Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively (note) [(link)](https://arxiv.org/pdf/2506.00396?)
- W4 - 9/25
  - [ACL 2025] A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive (note) [(link)](https://aclanthology.org/2025.acl-long.1454/)
  - âœ…[ACL 2024] Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models (note) [(link)](https://arxiv.org/abs/2401.07159)
  - âœ…[ACL 2025] Do LLMs Understand Dialogues? A Case Study on Dialogue Act [(note)](seminar/LLM/S1-W4-3.md) [(link)](https://aclanthology.org/2025.acl-long.1271/)
  - âœ…[ACL 2024] Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models (note) [(link)](https://arxiv.org/abs/2402.14848)
  - âœ…[ACL 2025] Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs (note) [(link)](https://arxiv.org/abs/2502.01926)
  - âœ…[ACL 2024] Mission: Impossible Language Models (note) [(link)](https://arxiv.org/abs/2401.06416)
  - âœ…[ACL 2025] HALoGEN: Fantastic LLM Hallucinations and Where to find them (note) [(link)](https://arxiv.org/abs/2501.08292)
  - âœ…[ACL 2025] FloorPlan-LLaMa: Aligning Architectsâ€™ Feedback and Domain Knowledge in Architectural Floor Plan Generation (note) [(link)](https://aclanthology.org/2025.acl-long.331/)
- W5 - 10/2 (Online)
  - [ACL 2025] Byte Latent Transformer: Patches Scale Better Than Tokens (note) [(link)](https://aclanthology.org/2025.acl-long.453/)
  - âœ…[ACL 2025] Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling (note) [(link)](https://aclanthology.org/2025.acl-long.338/)
  - [ACL 2025] Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability (note) [(link)](https://aclanthology.org/2025.acl-long.1508/)
  - [ACL 2025] Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs (note) [(link)](https://aclanthology.org/2025.acl-long.791/)
  - [EMNLP 2024] Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge (note) [(link)](https://arxiv.org/abs/2410.04784)
  - [ACL 2025] Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention (note) [(link)](https://arxiv.org/pdf/2410.12462)
  - [ACL 2025] Language Models Resist Alignment: Evidence From Data Compression (note) [(link)](https://aclanthology.org/2025.acl-long.1141/)
- W6 - 10/9 (Online)
  - [ACL 2025] A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens (note) [(link)](https://aclanthology.org/2025.acl-long.379/)
  - [EMNLP 2024] A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models (note) [(link)](https://aclanthology.org/2024.emnlp-main.210.pdf)
  - âœ…[ACL 2025] BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages (note) [(link)](https://aclanthology.org/2025.acl-long.436/)
  - [ACL 2025] Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention (note) [(link)](https://aclanthology.org/2025.acl-long.1126/)
  - âœ…[ACL 2025] Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems (note) [(link)](https://aclanthology.org/2025.acl-long.1259/)
  - [ACL 2025] Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details? (note) [(link)](https://aclanthology.org/2025.acl-long.1152/)
  - [EMNLP 2024] Towards Robust Speech Representation Learning for Thousands of Languages (note) [(link)](https://arxiv.org/pdf/2407.00837)
  - [ACL 2025] Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models (note) [(link)](https://aclanthology.org/2025.acl-long.374/)
  - âœ…[ACL 2024] L-Eval: Instituting Standardized Evaluation for Long Context Language Models (note) [(link)](https://aclanthology.org/2024.acl-long.776/)
  - [ACL 2025] Steering off Course: Reliability Challenges in Steering Language Models (note) [(link)](https://aclanthology.org/2025.acl-long.974.pdf)
  - [ACL 2024] Steering Llama 2 via Contrastive Activation Addition (note) [(link)](https://aclanthology.org/2024.acl-long.828/)

[Session 2] w/Professor Lee

- W7 - 10/16 - Benchmarking & Evaluation
  - âœ…[ACL 2025] YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering [(link)](https://arxiv.org/abs/2505.14279)
  - âœ…[ACL 2025] CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges [(link)](https://arxiv.org/abs/2410.15393)
  - âœ…[ICLR 2025] Beyond Scalar Reward Model: Learning Generative Judge from Preference Data [(link)](https://arxiv.org/abs/2410.03742)
  - âœ…[ACL 2025] M-RewardBench: Evaluating Reward Models in Multilingual Settings [(link)](https://arxiv.org/abs/2410.15522)
  - âœ…[COLM 2025] Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers [(link)](https://arxiv.org/abs/2502.20379)
- W8 - 10/23 - Reasoning Enhancement
  - âœ…[ICLR 2025] RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style
  - âœ…[ICLR 2025] SuperCorrect: Advancing Small LLM Reasoning with Thought Template Distillation and Self-Correction [(link)](https://arxiv.org/abs/2410.09008)
  - âœ…[NeurIPS 2025] Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning [(link)](https://arxiv.org/abs/2505.20161)
  - âœ…[arXiv 2025] Less is More: Recursive Reasoning with Tiny Networks [(link)](https://arxiv.org/abs/2510.04871)
  - âœ…[NeurIPS 2025] ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs [(link)](https://arxiv.org/abs/2506.18896)
  - âœ…[arXiv 2025] Learning to Reason without External Rewards [(link)](https://arxiv.org/abs/2505.19590)
  - âœ…[arXiv 2025] Deep Think with Confidence [(link)](https://arxiv.org/abs/2508.15260)
- W9 - 10/30 - Information Retrieval & Text Mining
  - âœ…[arXiv 2025] BMX: Entropy-weighted Similarity and Semantic-enhanced Lexical Search [(link)](https://arxiv.org/abs/2408.06643)
  - âœ…[COLM 2025] DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning [(link)](https://arxiv.org/abs/2503.00223)
  - âœ…[arXiv 2025] On the Theoretical Limitations of Embedding-Based Retrieval [(link)](https://arxiv.org/abs/2508.21038)
  - âœ…[COLM 2025] EnrichIndex: Using LLMs to Enrich Retrieval Indices Offline [(link)](https://arxiv.org/abs/2504.03598)
  - âœ…[arXiv 2025] FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS [(note)](seminar/LLM/S2-W9-5.md) [(link)](https://arxiv.org/abs/2505.16409)
  - âœ…MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem
  - âœ…[arXiv 2025] Towards Better Instruction Following Retrieval Models [(link)](https://arxiv.org/abs/2505.21439)
- W10 - 11/6 (Online) - Decision Making & Insight Generation
  - âœ…[NeurIPS 2025] Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop [(link)](https://arxiv.org/abs/2503.01013)
  - [NeurIPS 2024] From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection
  - âœ…[ACL 2025] INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent [(link)](https://arxiv.org/abs/2412.18174)
  - âœ…[ACL 2025] LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection [(link)](https://aclanthology.org/2025.acl-industry.9/)
  - âœ…[NeurIPS 2024] FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making [(link)](https://arxiv.org/abs/2407.06567)
  - âœ…[ICDM 2025] MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents [(link)](https://arxiv.org/abs/2502.00415)
  - âœ…[NeurIPS 2025] s3: You Don't Need That Much Data to Train a Search Agent via RL [(link)](https://arxiv.org/abs/2505.14146)
  - âœ…[ICLR 2025] DeLLMa: Decision Making Under Uncertainty with Large Language Models [(link)](https://arxiv.org/abs/2402.02392)
- W11 - 11/13 - Dialogue & Interactive System
  - âœ…[ACL 2025] In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents [(link)](https://arxiv.org/abs/2503.08026)
  - âœ…[NAACL 2025] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue [(link)](https://arxiv.org/abs/2406.05925)
  - âœ…[COLM 2025] Donâ€™t Lie to Your Friends: Learning What You Know from Collaborative Self-Play [(link)](https://arxiv.org/abs/2503.14481)
  - âœ…[NAACL 2025] Breaking ReAct Agents: Foot-in-the-Door Attack Will Get You In [(link)](https://arxiv.org/abs/2410.16950)
  - âœ…[NAACL 2025] AI-LieDar : Examine the Trade-off Between Utility and Truthfulness in LLM Agents [(link)](https://arxiv.org/abs/2409.09013)
  - âœ…[ACL 2025] Caution for the Environment: LLM Agents are Susceptible to Environmental Distractions [(link)](https://arxiv.org/abs/2408.02544)
  - âœ…[ICLR 2025] Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence [(link)](https://arxiv.org/abs/2407.07061)

[Session 3] w/Professor Kim

- W12 - 11/20
  - [NeurIPS 2025] CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding [(link)](https://arxiv.org/abs/2507.10449)
  - [NeurIPS 2024] RHO-1: Not All Tokens Are What You Need [(link)](https://arxiv.org/abs/2404.07965)
  - [ICML 2024] Debating with More Persuasive LLMs Leads to More Truthful Answers [(link)](https://arxiv.org/abs/2402.06782)
  - [ICLR 2025] A Probabilistic Perspective on Unlearning and Alignment for Large Language Models [(link)](https://arxiv.org/abs/2410.03523)
  - [ICML 2025] Medical Large Language Model Benchmarks Should Prioritize Construct Validity [(link)](https://arxiv.org/abs/2503.10694)
- W13 - 11/27
  - [ICML 2025] COLLABLLM: From Passive Responders to Active Collaborators [(link)](https://arxiv.org/abs/2502.00640)
  - [ICLR 2025] Your Mixture-Of-Experts LLM is Secretly An Embedding Model For Free [(link)](https://arxiv.org/abs/2410.10814)
  - [ICLR 2025] Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering [(link)](https://arxiv.org/abs/2410.15778)
  - [NeurIPS 2025] Large Language Diffusion Models [(link)](https://arxiv.org/abs/2502.09992)
  - [ICLR 2025] Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models [(link)](https://arxiv.org/abs/2411.14257)
  - [ICLR 2025] Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents [(link)](https://arxiv.org/abs/2410.05243)
- W14 - 12/4
  - [ICML 2025] SWE-Lancer: Can Frontier LLMs Earn \$1 Million from Real-World Freelance Software Engineering? [(link)](https://arxiv.org/abs/2502.12115)
  - [ICLR 2025] HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models [(link)](https://openreview.net/forum?id=TwJrTz9cRS)
  - [NeurIPS 2024] LLM Evaluators Recognize and Favor Their Own Generations [(link)](https://arxiv.org/abs/2404.13076)
  - [ICLR 2025] Self-Play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models [(link)](https://arxiv.org/abs/2406.13542)
  - [NeurIPS 2023] Jailbroken: How Does LLM Safety Training Fail? [(link)](https://arxiv.org/abs/2307.02483)
  - [NeurIPS 2025] Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond) [(link)](https://arxiv.org/abs/2510.22954)
  - [ICML 2023] A Watermark for Large Language Models [(link)](https://arxiv.org/abs/2301.10226)
- W15 - 12/11
  - [NeurIPS 2025] Reverse Engineering Human Preferences with Reinforcement Learning [(link)](https://arxiv.org/abs/2505.15795)
  - [ICLR 2025] MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions [(note)](seminar/LLM/S3-W15-2.md) [(link)](https://openreview.net/forum?id=GGlpykXDCa)
  - [NeurIPS 2024] Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction [(link)](https://arxiv.org/abs/2404.02905)
  - [ICML 2025] AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models [(link)](https://arxiv.org/abs/2501.16566)
  - [ICML 2025] Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality [(link)](https://arxiv.org/abs/2405.21060)
  - [NeurIPS 2024] Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts [(link)](https://arxiv.org/abs/2409.17106)
  - [ICML 2024] SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code [(link)](https://arxiv.org/abs/2403.01248)
  - [ICLR 2025] PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding [(link)](https://arxiv.org/abs/2501.16411)
  - [ICLR 2025] Do as We Do, Not as You Think: the Conformity of Large Language Models [(link)](https://arxiv.org/abs/2501.13381)
- W16 - 12/18
  - [ICLR 2025] On the Role of Attention Heads in Large Language Model Safety [(link)](https://arxiv.org/abs/2410.13708)
  - [ICLR 2025] From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions [(link)](https://arxiv.org/abs/2410.08197)
  - [NeurIPS 2025] Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model? [(link)](https://arxiv.org/abs/2504.13837)
  - [ICML 2025] Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition [(link)](https://arxiv.org/abs/2410.05603)
  - [ICML 2025] Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems [(link)](https://arxiv.org/abs/2505.00212)
  - [ICML 2025] Inference Scaling for Long-Context Retrieval Augmented Generation [(link)](https://arxiv.org/abs/2410.04343)
  - [ICLR 2024] Frozen Transformers in Language Models Are Effective Visual Encoder Layers [(link)](https://arxiv.org/abs/2310.12973)
  - [NeurIPS 2025] OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts [(link)](https://arxiv.org/abs/2507.05427)
